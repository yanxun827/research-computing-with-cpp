<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <title>Using a GPU as an Accelerator</title>
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <link rel="stylesheet" href="http://lab.hakim.se/reveal-js/css/reveal.min.css"/>
    <style type="text/css">code{white-space: pre;}</style>
    <link rel="stylesheet" href="http://lab.hakim.se/reveal-js/css/theme/night.css"/>
    <link rel="stylesheet" href="/research-computing-with-cpp//css/ucl_reveal.css"/>
    <link rel="stylesheet" href="/research-computing-with-cpp//site-styles/reveal.css"/>
  <link rel="stylesheet" media="print" href="http://lab.hakim.se/reveal-js/css/print/pdf.css" />
  <!--[if lt IE 9]>
  <script src="http://lab.hakim.se/reveal-js/lib/js/html5shiv.js"></script>
  <![endif]-->
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
    <h1 class="title">Using a GPU as an Accelerator</h1>
    <h3 class="date"></h3>
</section>

<section><section id="using-a-gpu-as-an-accelerator" class="titleslide slide level2"><h1>Using a GPU as an Accelerator</h1></section><section id="gpus-for-3d-graphics" class="slide level3">
<h1>GPUs for 3D graphics</h1>
<ul>
<li>3D graphics rendering involves lots of operations on 3 and 4 dimensional vectors
<ul>
<li>positions of vertices (x, y, z)</li>
<li>colour and transparency of pixels (RGBA)</li>
</ul></li>
<li>Realtime graphics rendering needs to be fast so accuracy is often sacrificed
<ul>
<li>GPUs are good at 32-bit integer and single precision floating point arithmetic</li>
<li>not as good at 64-bit integer and double precision floating point</li>
</ul></li>
<li>3D graphics operations are independent of one another
<ul>
<li>and can be performed in parallel</li>
</ul></li>
</ul>
</section><section id="gpus-as-multicore-vector-processors" class="slide level3">
<h1>GPUs as multicore vector processors</h1>
<ul>
<li>Multicore vector processors.</li>
<li>Much faster memory access to their own memory</li>
<li>Slow transfer between host and device (~5GB/s)</li>
<li>Constrained and complex access to different types of device memory</li>
<li>SIMD: Single Instruction, Multiple Data</li>
</ul>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Property</th>
<th style="text-align: left;">CPU</th>
<th style="text-align: left;">GPU</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">No of threads</td>
<td style="text-align: left;">&lt;10</td>
<td style="text-align: left;">1000s</td>
</tr>
<tr class="even">
<td style="text-align: left;">SIMD width</td>
<td style="text-align: left;">256 bits</td>
<td style="text-align: left;">1024 bits</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Memory bandwidth</td>
<td style="text-align: left;">&lt;25 GB/s</td>
<td style="text-align: left;">&lt;500 GB/s</td>
</tr>
</tbody>
</table>
</section><section id="gpu-hardware" class="slide level3">
<h1>GPU Hardware</h1>
<ul>
<li>Each core (multiprocessor - often abbreviated as &quot;SM&quot; or &quot;MP&quot;) has:
<ul>
<li>128 Single Precision Floating Point Units</li>
<li>32 Double Precision FPUs (that also perform single precision transcendental functions)</li>
<li>16384 32-bit registers (very fast access)</li>
<li>64KB of &quot;shared&quot; cache memory (fast access)</li>
<li>10KB of &quot;constant&quot; cache memory (writable by the CPU, fast, read-only access by the GPU)</li>
</ul></li>
<li>GPUs also have &quot;global&quot; memory which is the figure quoted by graphics card manufacturers (2GB, etc.)
<ul>
<li>accessed by the CPU across the PCI-Express bus</li>
<li>high latency, slow access by the GPU (but still up to 20x faster than CPU RAM access)</li>
</ul></li>
</ul>
</section><section id="general-purpose-programming-for-gpus" class="slide level3">
<h1>General Purpose Programming for GPUs</h1>
<ul>
<li>Threads are organised in groups of 32 called &quot;warps&quot;</li>
<li>Threads also organised &quot;Thread blocks&quot; of several warps</li>
<li>&quot;Thread blocks&quot; are organised in 1-d, 2-d, or 4-d grids</li>
<li>&quot;Thread blocks&quot; are assigned to Streaming Multiprocessors</li>
<li>A GPU cards is contains 1-50 Streaming Multiprocessor</li>
</ul>
</section><section id="gpu-architecture" class="slide level3">
<h1>GPU Architecture</h1>
<figure>
<img src="figures/pgi-nvidia-block-diagram.png" />
</figure>
<p>See <a href="http://www.gris.informatik.tu-darmstadt.de/cuda-workshop/tutorial/Advanced_CUDA_01.pdf">more</a></p>
</section><section id="simt" class="slide level3">
<h1>SIMT</h1>
<ul>
<li>Threads within a block have access to the same &quot;shared&quot; memory</li>
<li>Threads within a block can synchronise</li>
<li>No communication or synchronisation primitives across blocks/SMs
<ul>
<li>can use atomic operations on variables in global memory (slow)</li>
</ul></li>
<li>This type of programming is a hybrid between threaded programming and SIMD and hence is called SIMT by Nvidia</li>
</ul>
</section><section id="executing-code-on-the-gpu" class="slide level3">
<h1>Executing code on the GPU</h1>
<ul>
<li>Functions executed on the GPU and called from the CPU are called &quot;kernels&quot;
<ul>
<li>kernel execution is asynchronous to the CPU</li>
<li>CPU must call a function which blocks until the GPU has finished executing the current kernel before attempting to download results</li>
<li>there is an implicit synchronisation barrier on the GPU at the start of each kernel</li>
</ul></li>
<li>Common programming pattern:
<ul>
<li>upload data from CPU RAM to GPU global memory (slow)</li>
<li>execute kernel(s) on GPU (fast)</li>
<li>synchronise</li>
<li>download results (slow)</li>
</ul></li>
</ul>
</section><section id="gpu-accelerating-your-code" class="slide level3">
<h1>GPU-accelerating your code</h1>
<ul>
<li>Four options to GPU accelerate code:
<ul>
<li>replace existing libraries with GPU-accelerated ones (<a href="https://arrayfire.com/">ArrayFire</a>, <a href="https://developer.nvidia.com/cufft">cuFFT</a>, <a href="https://developer.nvidia.com/cublas">cuBLAS</a>, <a href="http://icl.cs.utk.edu/magma/">Magma</a>, ...)</li>
<li>use compiler directives to automatically generate GPU-accelerated portions of code (OpenMP 4.5, <a href="http://www.openacc.org/">OpenACC</a>)</li>
<li>use CUDA::Thrust C++ template library to build your own kernels</li>
<li>write your own kernels in CUDA-C</li>
</ul></li>
</ul>
</section></section>
    </div>
  </div>

  <script src="http://lab.hakim.se/reveal-js/lib/js/head.min.js"></script>
  <script src="http://lab.hakim.se/reveal-js/js/reveal.min.js"></script>

  <script>

      // Full list of configuration options available here:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,
        theme: 'night', // available themes are in /css/theme
        transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none

        // Optional libraries used to extend on reveal.js
        dependencies: [
          { src: 'http://lab.hakim.se/reveal-js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'http://lab.hakim.se/reveal-js/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
          { src: 'http://lab.hakim.se/reveal-js/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } },
//          { src: 'http://lab.hakim.se/reveal-js/plugin/search/search.js', async: true, condition: function() { return !!document.body.classList; }, }
//          { src: 'http://lab.hakim.se/reveal-js/plugin/remotes/remotes.js', async: true, condition: function() { return !!document.body.classList; } }
]});
    </script>
  </body>
</html>
